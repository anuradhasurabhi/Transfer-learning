def evaluate_model(model, descriptions, photos, tokenizer, max_length):
 actual, predicted = list(), list()
 # step over the whole set
 for key, desc_list in descriptions.items():
  # generate description
  yhat = generate_desc(model, tokenizer, photos[key], max_length)
  # store actual and predicted
  references = [d.split() for d in desc_list]
  actual.append(references)
  predicted.append(yhat.split())
 # calculate BLEU score
 print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))
 print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))
 print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))
 print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))

filename = test_path
test = load_set(filename)
print('Dataset: %d' % len(test))
# descriptions
test_descriptions = load_clean_descriptions('descriptions.txt', test)
print('Descriptions: test=%d' % len(test_descriptions))
# photo features
test_features = load_photo_features('features.pkl', test)
print('Photos: test=%d' % len(test_features))

import numpy as np
# load the model
filename = 'model-ep014-loss2.569-val_loss4.723.h5'
model = load_model(filename)
# evaluate model
evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)
